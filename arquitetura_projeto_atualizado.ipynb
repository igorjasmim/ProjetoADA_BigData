{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando Variáveis de Ambiente do Arquivo .env\n",
    "\n",
    "Usamos python-dotenv para carregar as variáveis de ambiente do arquivo .env.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine, text\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import time\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "# Carregar variáveis do arquivo .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuração do Ambiente Spark\n",
    "\n",
    "Configuramos a sessão do Spark para otimizar o processamento de grandes volumes de dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recriar a sessão Spark usando as configurações locais definidas em spark-defaults.conf\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"HiveTableCreation\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configurações adicionais do Hive\n",
    "spark.conf.set(\"hive.metastore.warehouse.dir\", \"file:///C:/spark/hive/warehouse\")\n",
    "spark.conf.set(\"hive.metastore.uri\", \"thrift://localhost:9083\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando o Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão do Spark: 3.5.0\n",
      "Spark está levantado e funcional.\n"
     ]
    }
   ],
   "source": [
    "# Verificação do Spark\n",
    "try:\n",
    "    # Exibir a versão do Spark para verificar se está funcional\n",
    "    print(f\"Versão do Spark: {spark.version}\")\n",
    "    print(\"Spark está levantado e funcional.\")\n",
    "except Exception as e:\n",
    "    print(\"Erro ao levantar o Spark:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando o Hadoop [Usando o Power Shell]\n",
    "\n",
    "Para que o Hadoop funcione normalmente em ambiente de aprendizagem, onde a máquina local é desligada e depois ligada para novas operações, será necessário no Power Shell como administrador (win + x) executar os comandos a seguir a partir da pasta `C:\\hadoop\\sbin`:\n",
    "\n",
    "1. **Verificar e remover processos usando portas específicas:**\n",
    "\n",
    "    ```powershell\n",
    "    netstat -ano | findstr :9000\n",
    "    taskkill /PID <PID> /F\n",
    "\n",
    "    netstat -ano | findstr :9866\n",
    "    taskkill /PID <PID> /F\n",
    "    ```\n",
    "\n",
    "2. **Obter o nome de usuário e conceder permissões:**\n",
    "\n",
    "    ```powershell\n",
    "    whoami /user  # Pegue no resultado desse comando seu nome de usuário (até a barra \"\\\")\n",
    "    ```\n",
    "\n",
    "    ```powershell\n",
    "    icacls \"C:\\hadoop\\data\\namenode\" /grant \"<user>:F\" /T\n",
    "    icacls \"C:\\hadoop\\data\\datanode\" /grant \"<user>:F\" /T\n",
    "    ```\n",
    "\n",
    "3. **Remover dados antigos das pastas do DataNode e NameNode:**\n",
    "\n",
    "    ```powershell\n",
    "    Remove-Item -Path \"C:\\hadoop\\data\\datanode\\*\" -Recurse -Force\n",
    "    Remove-Item -Path \"C:\\hadoop\\data\\namenode\\*\" -Recurse -Force\n",
    "    ```\n",
    "\n",
    "4. **Formatar o NameNode e iniciar serviços do Hadoop:**\n",
    "\n",
    "    ```powershell\n",
    "    hdfs namenode -status  # Aguarde até realizar todos os processos. Responda Y se solicitado.\n",
    "    .\\start-dfs.cmd  # Aguarde até a conclusão dos processos.\n",
    "    .\\start-yarn.cmd  # Ativar o processo YARN.\n",
    "    ```\n",
    "\n",
    "5. **Acessar as URLs do Hadoop para verificar:**\n",
    "\n",
    "    - HDFS: [http://localhost:9870/](http://localhost:9870/)\n",
    "    - YARN: [http://localhost:8088/](http://localhost:8088/)\n",
    "\n",
    "### Comandos HDFS\n",
    "\n",
    "1. **Criar uma pasta no cluster:**\n",
    "\n",
    "    ```powershell\n",
    "    hdfs dfs -mkdir -p /nome_pasta\n",
    "    ```\n",
    "\n",
    "2. **Remover um arquivo específico no cluster:**\n",
    "\n",
    "    ```powershell\n",
    "    hdfs dfs -rm -r /dados/arquivo.parquet\n",
    "    ```\n",
    "\n",
    "3. **Setar permissões para uma pasta ou arquivo:**\n",
    "\n",
    "    ```powershell\n",
    "    hdfs dfs -chmod -R 755 /dados/arquivo.parquet\n",
    "    ```\n",
    "\n",
    "4. **Exibir metadados do arquivo no caminho especificado:**\n",
    "\n",
    "    ```powershell\n",
    "    hdfs dfs -ls /dados/arquivo.parquet\n",
    "    ```\n",
    "\n",
    "5. **Exibir os arquivos na raiz do cluster:**\n",
    "\n",
    "    ```powershell\n",
    "    hdfs dfs -ls /\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvar o CSV no formato PARQUET no HDFS\n",
    "\n",
    "Lemos os dados do arquivo `temas_ambientais.csv`, e salvamos no HDFS.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando leitura do arquivo CSV e conversão para Parquet no HDFS\n",
      "Arquivo salvo com sucesso no HDFS: hdfs://localhost:9000/dados/temas_ambientais.parquet\n",
      "Total de registros: 6839104\n",
      "Schema do DataFrame:\n",
      "root\n",
      " |-- uf: string (nullable = true)\n",
      " |-- municipio: string (nullable = true)\n",
      " |-- codigo_ibge: integer (nullable = true)\n",
      " |-- area_do_imovel: double (nullable = true)\n",
      " |-- registro_car: string (nullable = true)\n",
      " |-- situacao_cadastro: string (nullable = true)\n",
      " |-- condicao_cadastro: string (nullable = true)\n",
      " |-- area_liquida: double (nullable = true)\n",
      " |-- area_remanescente_vegetacao_nativa: double (nullable = true)\n",
      " |-- area_reserva_legal_proposta: double (nullable = true)\n",
      " |-- area_preservacao_permanente: double (nullable = true)\n",
      " |-- area_nao_classificada: double (nullable = true)\n",
      " |-- solicitacao_adesao_pra: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- data_inscricao: timestamp (nullable = true)\n",
      " |-- data_alteracao_condicao_cadastro: timestamp (nullable = true)\n",
      " |-- area_rural_consolidada: double (nullable = true)\n",
      " |-- area_servidao_administrativa: double (nullable = true)\n",
      " |-- tipo_imovel_rural: string (nullable = true)\n",
      " |-- modulos_fiscais: double (nullable = true)\n",
      " |-- area_uso_restrito: double (nullable = true)\n",
      " |-- area_reserva_legal_averbada: double (nullable = true)\n",
      " |-- area_reserva_legal_aprovada_nao_averbada: double (nullable = true)\n",
      " |-- area_pousio: double (nullable = true)\n",
      " |-- data_ultima_retificacao: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hdfs_parquet_path = None\n",
    "\n",
    "try:\n",
    "    print(\"Iniciando leitura do arquivo CSV e conversão para Parquet no HDFS\")\n",
    "    \n",
    "    # Caminho local do arquivo CSV\n",
    "    csv_path = \"data/temas_ambientais.csv\"\n",
    "    \n",
    "    # Caminho no HDFS para salvar o Parquet\n",
    "    hdfs_parquet_path = \"hdfs://localhost:9000/dados/temas_ambientais.parquet\"\n",
    "    \n",
    "    # Leitura do CSV com o separador ';'\n",
    "    df = spark.read.csv(csv_path, header=True, inferSchema=True, sep=';')\n",
    "    \n",
    "    # Salvamento em Parquet no HDFS\n",
    "    df.write.mode(\"overwrite\").parquet(hdfs_parquet_path)\n",
    "    \n",
    "    print(f\"Arquivo salvo com sucesso no HDFS: {hdfs_parquet_path}\")\n",
    "    print(f\"Total de registros: {df.count()}\")\n",
    "    print(\"Schema do DataFrame:\")\n",
    "    df.printSchema()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro no processamento: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modificar o nome das Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para formatar nomes de colunas (remover underscores e capitalizar)\n",
    "def format_column_name(col_name):\n",
    "    return ' '.join(word.capitalize() for word in col_name.split('_'))\n",
    "\n",
    "# Ler o DataFrame Parquet\n",
    "df = spark.read.parquet(hdfs_parquet_path)\n",
    "\n",
    "# Renomear colunas\n",
    "for old_col in df.columns:\n",
    "    new_col = format_column_name(old_col)\n",
    "    df = df.withColumnRenamed(old_col, new_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criar tabela temporária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nome da tabela Hive\n",
    "table_name = \"temas_ambientais\"\n",
    "\n",
    "# Dropar tabela existente\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "\n",
    "# Criar view temporária\n",
    "df.createOrReplaceTempView(\"temp_table\")\n",
    "\n",
    "# Comando SQL para criar tabela Hive\n",
    "create_table_sql = f\"\"\"\n",
    "  CREATE TABLE IF NOT EXISTS {table_name}\n",
    "  STORED AS PARQUET\n",
    "  LOCATION '{hdfs_parquet_path}'\n",
    "  AS SELECT * FROM temp_table\n",
    "\"\"\"\n",
    "\n",
    "# Executar criação da tabela\n",
    "spark.sql(create_table_sql)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Consulta SQL usando Hive com medição de tempo\n",
    "\n",
    "Exibimos informações úteis sobre o tempo de consultas SQL usando o Hive no Dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de consulta SQL: 0.63 segundos\n",
      "Número de linhas no DataFrame: 13678208\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uf</th>\n",
       "      <th>Municipio</th>\n",
       "      <th>Codigo Ibge</th>\n",
       "      <th>Area Do Imovel</th>\n",
       "      <th>Registro Car</th>\n",
       "      <th>Situacao Cadastro</th>\n",
       "      <th>Condicao Cadastro</th>\n",
       "      <th>Area Liquida</th>\n",
       "      <th>Area Remanescente Vegetacao Nativa</th>\n",
       "      <th>Area Reserva Legal Proposta</th>\n",
       "      <th>...</th>\n",
       "      <th>Data Alteracao Condicao Cadastro</th>\n",
       "      <th>Area Rural Consolidada</th>\n",
       "      <th>Area Servidao Administrativa</th>\n",
       "      <th>Tipo Imovel Rural</th>\n",
       "      <th>Modulos Fiscais</th>\n",
       "      <th>Area Uso Restrito</th>\n",
       "      <th>Area Reserva Legal Averbada</th>\n",
       "      <th>Area Reserva Legal Aprovada Nao Averbada</th>\n",
       "      <th>Area Pousio</th>\n",
       "      <th>Data Ultima Retificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PA</td>\n",
       "      <td>Melgaço</td>\n",
       "      <td>1504505</td>\n",
       "      <td>8.6572</td>\n",
       "      <td>PA-1504505-60C7BD9561D442D3A35BC962553E3593</td>\n",
       "      <td>AT</td>\n",
       "      <td>Aguardando análise, não passível de revisão de...</td>\n",
       "      <td>8.6572</td>\n",
       "      <td>8.657153</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-05-06 04:24:49.156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.1237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-05-06 04:24:33.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PA</td>\n",
       "      <td>Melgaço</td>\n",
       "      <td>1504505</td>\n",
       "      <td>8.9118</td>\n",
       "      <td>PA-1504505-38CEB3B058ED45DFB94267ADB879921F</td>\n",
       "      <td>AT</td>\n",
       "      <td>Aguardando análise, não passível de revisão de...</td>\n",
       "      <td>8.9118</td>\n",
       "      <td>8.911800</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-05-06 04:25:25.227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.1273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-05-06 04:25:08.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PA</td>\n",
       "      <td>Vitória do Xingu</td>\n",
       "      <td>1508357</td>\n",
       "      <td>541.3827</td>\n",
       "      <td>PA-1508357-F2AD1C32877C492689615CCEF1F0D7CA</td>\n",
       "      <td>PE</td>\n",
       "      <td>Analisado com pendências, aguardando retificaç...</td>\n",
       "      <td>541.3827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89.4643</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-05-23 23:03:40.040</td>\n",
       "      <td>450.127674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IRU</td>\n",
       "      <td>7.2184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-05-06 04:25:44.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CE</td>\n",
       "      <td>Cascavel</td>\n",
       "      <td>2303501</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>CE-2303501-9A25D7359BBC4C21A57856A2DFA6391D</td>\n",
       "      <td>AT</td>\n",
       "      <td>Aguardando análise, não passível de revisão de...</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-05-06 04:30:34.965</td>\n",
       "      <td>0.083406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-05-06 04:30:18.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP</td>\n",
       "      <td>Borborema</td>\n",
       "      <td>3507407</td>\n",
       "      <td>64.2994</td>\n",
       "      <td>SP-3507407-2DAD18BEF2AA46CE9A8F550332055488</td>\n",
       "      <td>AT</td>\n",
       "      <td>Revisado, aguardando análise da equipe</td>\n",
       "      <td>64.3080</td>\n",
       "      <td>0.794852</td>\n",
       "      <td>0.7949</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-06-09 11:08:09.043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IRU</td>\n",
       "      <td>4.0192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-05-06 05:00:55.199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Uf         Municipio  Codigo Ibge  Area Do Imovel  \\\n",
       "0  PA           Melgaço      1504505          8.6572   \n",
       "1  PA           Melgaço      1504505          8.9118   \n",
       "2  PA  Vitória do Xingu      1508357        541.3827   \n",
       "3  CE          Cascavel      2303501          0.0845   \n",
       "4  SP         Borborema      3507407         64.2994   \n",
       "\n",
       "                                  Registro Car Situacao Cadastro  \\\n",
       "0  PA-1504505-60C7BD9561D442D3A35BC962553E3593                AT   \n",
       "1  PA-1504505-38CEB3B058ED45DFB94267ADB879921F                AT   \n",
       "2  PA-1508357-F2AD1C32877C492689615CCEF1F0D7CA                PE   \n",
       "3  CE-2303501-9A25D7359BBC4C21A57856A2DFA6391D                AT   \n",
       "4  SP-3507407-2DAD18BEF2AA46CE9A8F550332055488                AT   \n",
       "\n",
       "                                   Condicao Cadastro  Area Liquida  \\\n",
       "0  Aguardando análise, não passível de revisão de...        8.6572   \n",
       "1  Aguardando análise, não passível de revisão de...        8.9118   \n",
       "2  Analisado com pendências, aguardando retificaç...      541.3827   \n",
       "3  Aguardando análise, não passível de revisão de...        0.0845   \n",
       "4             Revisado, aguardando análise da equipe       64.3080   \n",
       "\n",
       "   Area Remanescente Vegetacao Nativa  Area Reserva Legal Proposta  ...  \\\n",
       "0                            8.657153                       0.0000  ...   \n",
       "1                            8.911800                       0.0000  ...   \n",
       "2                            0.000000                      89.4643  ...   \n",
       "3                            0.000000                       0.0000  ...   \n",
       "4                            0.794852                       0.7949  ...   \n",
       "\n",
       "   Data Alteracao Condicao Cadastro  Area Rural Consolidada  \\\n",
       "0           2022-05-06 04:24:49.156                0.000000   \n",
       "1           2022-05-06 04:25:25.227                0.000000   \n",
       "2           2022-05-23 23:03:40.040              450.127674   \n",
       "3           2022-05-06 04:30:34.965                0.083406   \n",
       "4           2022-06-09 11:08:09.043                0.000000   \n",
       "\n",
       "  Area Servidao Administrativa  Tipo Imovel Rural  Modulos Fiscais  \\\n",
       "0                          0.0                IRU           0.1237   \n",
       "1                          0.0                IRU           0.1273   \n",
       "2                          0.0                IRU           7.2184   \n",
       "3                          0.0                IRU           0.0030   \n",
       "4                          0.0                IRU           4.0192   \n",
       "\n",
       "  Area Uso Restrito Area Reserva Legal Averbada  \\\n",
       "0               0.0                         0.0   \n",
       "1               0.0                         0.0   \n",
       "2               0.0                         0.0   \n",
       "3               0.0                         0.0   \n",
       "4               0.0                         0.0   \n",
       "\n",
       "   Area Reserva Legal Aprovada Nao Averbada  Area Pousio  \\\n",
       "0                                       0.0          0.0   \n",
       "1                                       0.0          0.0   \n",
       "2                                       0.0          0.0   \n",
       "3                                       0.0          0.0   \n",
       "4                                       0.0          0.0   \n",
       "\n",
       "  Data Ultima Retificacao  \n",
       "0 2022-05-06 04:24:33.206  \n",
       "1 2022-05-06 04:25:08.862  \n",
       "2 2022-05-06 04:25:44.570  \n",
       "3 2022-05-06 04:30:18.634  \n",
       "4 2022-05-06 05:00:55.199  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estrutura da Tabela:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>col_name</th><th>data_type</th><th>comment</th></tr>\n",
       "<tr><td>Uf</td><td>string</td><td>NULL</td></tr>\n",
       "<tr><td>Municipio</td><td>string</td><td>NULL</td></tr>\n",
       "<tr><td>Codigo Ibge</td><td>int</td><td>NULL</td></tr>\n",
       "<tr><td>Area Do Imovel</td><td>double</td><td>NULL</td></tr>\n",
       "<tr><td>Registro Car</td><td>string</td><td>NULL</td></tr>\n",
       "<tr><td>Situacao Cadastro</td><td>string</td><td>NULL</td></tr>\n",
       "<tr><td>Condicao Cadastro</td><td>string</td><td>NULL</td></tr>\n",
       "<tr><td>Area Liquida</td><td>double</td><td>NULL</td></tr>\n",
       "<tr><td>Area Remanescente...</td><td>double</td><td>NULL</td></tr>\n",
       "<tr><td>Area Reserva Lega...</td><td>double</td><td>NULL</td></tr>\n",
       "<tr><td>Area Preservacao ...</td><td>double</td><td>NULL</td></tr>\n",
       "<tr><td>Area Nao Classifi...</td><td>double</td><td>NULL</td></tr>\n",
       "<tr><td>Solicitacao Adesa...</td><td>string</td><td>NULL</td></tr>\n",
       "<tr><td>Latitude</td><td>double</td><td>NULL</td></tr>\n",
       "<tr><td>Longitude</td><td>double</td><td>NULL</td></tr>\n",
       "<tr><td>Data Inscricao</td><td>timestamp</td><td>NULL</td></tr>\n",
       "<tr><td>Data Alteracao Co...</td><td>timestamp</td><td>NULL</td></tr>\n",
       "<tr><td>Area Rural Consol...</td><td>double</td><td>NULL</td></tr>\n",
       "<tr><td>Area Servidao Adm...</td><td>double</td><td>NULL</td></tr>\n",
       "<tr><td>Tipo Imovel Rural</td><td>string</td><td>NULL</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------------------+---------+-------+\n",
       "|            col_name|data_type|comment|\n",
       "+--------------------+---------+-------+\n",
       "|                  Uf|   string|   NULL|\n",
       "|           Municipio|   string|   NULL|\n",
       "|         Codigo Ibge|      int|   NULL|\n",
       "|      Area Do Imovel|   double|   NULL|\n",
       "|        Registro Car|   string|   NULL|\n",
       "|   Situacao Cadastro|   string|   NULL|\n",
       "|   Condicao Cadastro|   string|   NULL|\n",
       "|        Area Liquida|   double|   NULL|\n",
       "|Area Remanescente...|   double|   NULL|\n",
       "|Area Reserva Lega...|   double|   NULL|\n",
       "|Area Preservacao ...|   double|   NULL|\n",
       "|Area Nao Classifi...|   double|   NULL|\n",
       "|Solicitacao Adesa...|   string|   NULL|\n",
       "|            Latitude|   double|   NULL|\n",
       "|           Longitude|   double|   NULL|\n",
       "|      Data Inscricao|timestamp|   NULL|\n",
       "|Data Alteracao Co...|timestamp|   NULL|\n",
       "|Area Rural Consol...|   double|   NULL|\n",
       "|Area Servidao Adm...|   double|   NULL|\n",
       "|   Tipo Imovel Rural|   string|   NULL|\n",
       "+--------------------+---------+-------+\n",
       "only showing top 20 rows"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configurar exibição\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "\n",
    "# Início do temporizador para consulta\n",
    "tempo_inicio_consulta = time.time()\n",
    "\n",
    "# Executar a consulta completa sem limitar o DataFrame\n",
    "resultado = spark.sql(f\"SELECT * FROM {table_name}\")\n",
    "numero_de_linhas = resultado.count()\n",
    "tempo_consulta = time.time() - tempo_inicio_consulta\n",
    "\n",
    "# Exibir os resultados da consulta\n",
    "print(f\"Tempo de consulta SQL: {tempo_consulta:.2f} segundos\")\n",
    "print(f\"Número de linhas no DataFrame: {numero_de_linhas}\")\n",
    "\n",
    "# Usar display para mostrar o DataFrame no Jupyter Notebook\n",
    "display(resultado.limit(5).toPandas())\n",
    "\n",
    "# Exibir o schema da tabela\n",
    "print(\"\\nEstrutura da Tabela:\")\n",
    "display(spark.sql(f\"DESCRIBE {table_name}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeira Consulta SQL usando Hive do Projeto\n",
    "\n",
    "Recupere a soma de área que é a coluna \"Area Do Imovel\" para todas as propriedades agrícolas que pertecem ao MS e MT que estão na coluna \"Uf\". Ordene o resultado em ordem descrescente.\n",
    "\n",
    "***Obs: Crie a pasta para a tabela Hive. Use o comando \"hdfs dfs -mkdir -p /tmp/hive\" no Power Shell como Administrador***.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela projeto_consulta_1 criada no HDFS com os resultados da consulta 1.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uf</th>\n",
       "      <th>Soma_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MT</td>\n",
       "      <td>8.458709e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MS</td>\n",
       "      <td>3.632188e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Uf     Soma_Area\n",
       "0  MT  8.458709e+07\n",
       "1  MS  3.632188e+07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas no DataFrame: 2\n",
      "\n",
      "Tempo total de execução: 3.63 segundos\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Início do temporizador total\n",
    "    tempo_inicio_total = time.time()   \n",
    "\n",
    "    # Consulta SQL: Soma da Área para MS e MT\n",
    "    consulta_1 = \"\"\"\n",
    "    SELECT Uf, SUM(`Area Do Imovel`) AS Soma_Area\n",
    "    FROM temp_table\n",
    "    WHERE Uf IN ('MS', 'MT')\n",
    "    GROUP BY Uf\n",
    "    ORDER BY Soma_Area DESC\n",
    "    \"\"\"\n",
    "\n",
    "    # Salvar os resultados da consulta no HDFS\n",
    "    df_consulta_1 = spark.sql(consulta_1)  # Primeira consulta do projeto\n",
    "    table_consulta_1 = \"projeto_consulta_1\"\n",
    "    df_consulta_1.write.mode(\"overwrite\").parquet(f\"hdfs://localhost:9000/tmp/hive/{table_consulta_1}\")\n",
    "    print(f\"Tabela {table_consulta_1} criada no HDFS com os resultados da consulta 1.\")\n",
    "    \n",
    "    # Ler a tabela criada no HDFS e exibir os resultados completos\n",
    "    consulta_1 = spark.read.parquet(f\"hdfs://localhost:9000/tmp/hive/{table_consulta_1}\")\n",
    "    numero_de_linhas = consulta_1.count()\n",
    "    display(consulta_1.limit(5).toPandas())    \n",
    "    print(f\"Número de linhas no DataFrame: {numero_de_linhas}\") \n",
    "\n",
    "    # Tempo total de execução\n",
    "    tempo_total = time.time() - tempo_inicio_total\n",
    "    print(f\"\\nTempo total de execução: {tempo_total:.2f} segundos\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro no processamento: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segunda Consulta SQL usando Hive do Projeto\n",
    "\n",
    "filtrar todas as propriedades que pertencem à região sudeste do Brasil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela projeto_consulta_2 criada no HDFS com os resultados da consulta 2.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uf</th>\n",
       "      <th>Municipio</th>\n",
       "      <th>Codigo Ibge</th>\n",
       "      <th>Area Do Imovel</th>\n",
       "      <th>Registro Car</th>\n",
       "      <th>Situacao Cadastro</th>\n",
       "      <th>Condicao Cadastro</th>\n",
       "      <th>Area Liquida</th>\n",
       "      <th>Area Remanescente Vegetacao Nativa</th>\n",
       "      <th>Area Reserva Legal Proposta</th>\n",
       "      <th>...</th>\n",
       "      <th>Data Alteracao Condicao Cadastro</th>\n",
       "      <th>Area Rural Consolidada</th>\n",
       "      <th>Area Servidao Administrativa</th>\n",
       "      <th>Tipo Imovel Rural</th>\n",
       "      <th>Modulos Fiscais</th>\n",
       "      <th>Area Uso Restrito</th>\n",
       "      <th>Area Reserva Legal Averbada</th>\n",
       "      <th>Area Reserva Legal Aprovada Nao Averbada</th>\n",
       "      <th>Area Pousio</th>\n",
       "      <th>Data Ultima Retificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP</td>\n",
       "      <td>Brodowski</td>\n",
       "      <td>3507803</td>\n",
       "      <td>7.2293</td>\n",
       "      <td>SP-3507803-EF2877CFB21F4443BF3B7F8665ED3164</td>\n",
       "      <td>AT</td>\n",
       "      <td>Revisado, aguardando aceite pelo proprietário</td>\n",
       "      <td>7.2368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-02-03 13:15:22.810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-05-09 22:53:32.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP</td>\n",
       "      <td>Dracena</td>\n",
       "      <td>3514403</td>\n",
       "      <td>22.2074</td>\n",
       "      <td>SP-3514403-51883E2CA225418DA0153F9CEE900C90</td>\n",
       "      <td>AT</td>\n",
       "      <td>Revisado, aguardando aceite pelo proprietário</td>\n",
       "      <td>22.1915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-02-04 07:53:04.730</td>\n",
       "      <td>0.751033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>IRU</td>\n",
       "      <td>1.1104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-05-09 22:53:36.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MG</td>\n",
       "      <td>Pimenta</td>\n",
       "      <td>3150505</td>\n",
       "      <td>8.2017</td>\n",
       "      <td>MG-3150505-F68352DCF0B840C68D04D752DC71FADF</td>\n",
       "      <td>AT</td>\n",
       "      <td>Aguardando análise, não passível de revisão de...</td>\n",
       "      <td>8.2017</td>\n",
       "      <td>0.394558</td>\n",
       "      <td>0.3946</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7.796744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-05-09 22:53:37.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP</td>\n",
       "      <td>Paraguaçu Paulista</td>\n",
       "      <td>3535507</td>\n",
       "      <td>19.8508</td>\n",
       "      <td>SP-3535507-4AE4E04B91AF484185E20160AD1A3ADE</td>\n",
       "      <td>AT</td>\n",
       "      <td>Revisado, aguardando aceite pelo proprietário</td>\n",
       "      <td>19.6332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-09-10 11:29:42.531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202827</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-05-09 22:53:40.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP</td>\n",
       "      <td>Laranjal Paulista</td>\n",
       "      <td>3526407</td>\n",
       "      <td>6.7043</td>\n",
       "      <td>SP-3526407-0C2A559800844D26BDC7D34D0D74DD22</td>\n",
       "      <td>AT</td>\n",
       "      <td>Revisado, aguardando aceite pelo proprietário</td>\n",
       "      <td>6.6269</td>\n",
       "      <td>0.451086</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-09-09 22:44:35.084</td>\n",
       "      <td>0.084980</td>\n",
       "      <td>0.086547</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.3677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-05-09 22:53:44.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Uf           Municipio  Codigo Ibge  Area Do Imovel  \\\n",
       "0  SP           Brodowski      3507803          7.2293   \n",
       "1  SP             Dracena      3514403         22.2074   \n",
       "2  MG             Pimenta      3150505          8.2017   \n",
       "3  SP  Paraguaçu Paulista      3535507         19.8508   \n",
       "4  SP   Laranjal Paulista      3526407          6.7043   \n",
       "\n",
       "                                  Registro Car Situacao Cadastro  \\\n",
       "0  SP-3507803-EF2877CFB21F4443BF3B7F8665ED3164                AT   \n",
       "1  SP-3514403-51883E2CA225418DA0153F9CEE900C90                AT   \n",
       "2  MG-3150505-F68352DCF0B840C68D04D752DC71FADF                AT   \n",
       "3  SP-3535507-4AE4E04B91AF484185E20160AD1A3ADE                AT   \n",
       "4  SP-3526407-0C2A559800844D26BDC7D34D0D74DD22                AT   \n",
       "\n",
       "                                   Condicao Cadastro  Area Liquida  \\\n",
       "0      Revisado, aguardando aceite pelo proprietário        7.2368   \n",
       "1      Revisado, aguardando aceite pelo proprietário       22.1915   \n",
       "2  Aguardando análise, não passível de revisão de...        8.2017   \n",
       "3      Revisado, aguardando aceite pelo proprietário       19.6332   \n",
       "4      Revisado, aguardando aceite pelo proprietário        6.6269   \n",
       "\n",
       "   Area Remanescente Vegetacao Nativa  Area Reserva Legal Proposta  ...  \\\n",
       "0                            0.000000                       0.0000  ...   \n",
       "1                            0.000000                       0.0000  ...   \n",
       "2                            0.394558                       0.3946  ...   \n",
       "3                            0.000000                       0.0000  ...   \n",
       "4                            0.451086                       0.0000  ...   \n",
       "\n",
       "   Data Alteracao Condicao Cadastro  Area Rural Consolidada  \\\n",
       "0           2022-02-03 13:15:22.810                0.000000   \n",
       "1           2022-02-04 07:53:04.730                0.751033   \n",
       "2                               NaT                7.796744   \n",
       "3           2022-09-10 11:29:42.531                0.000000   \n",
       "4           2022-09-09 22:44:35.084                0.084980   \n",
       "\n",
       "  Area Servidao Administrativa  Tipo Imovel Rural  Modulos Fiscais  \\\n",
       "0                     0.000000                IRU           0.0000   \n",
       "1                     0.000000                IRU           1.1104   \n",
       "2                     0.000000                IRU           0.2300   \n",
       "3                     0.202827                IRU           0.9824   \n",
       "4                     0.086547                IRU           0.3677   \n",
       "\n",
       "  Area Uso Restrito Area Reserva Legal Averbada  \\\n",
       "0               0.0                         0.0   \n",
       "1               0.0                         0.0   \n",
       "2               0.0                         0.0   \n",
       "3               0.0                         0.0   \n",
       "4               0.0                         0.0   \n",
       "\n",
       "   Area Reserva Legal Aprovada Nao Averbada  Area Pousio  \\\n",
       "0                                       0.0          0.0   \n",
       "1                                       0.0          0.0   \n",
       "2                                       0.0          0.0   \n",
       "3                                       0.0          0.0   \n",
       "4                                       0.0          0.0   \n",
       "\n",
       "  Data Ultima Retificacao  \n",
       "0 2015-05-09 22:53:32.800  \n",
       "1 2015-05-09 22:53:36.283  \n",
       "2 2015-05-09 22:53:37.507  \n",
       "3 2015-05-09 22:53:40.686  \n",
       "4 2015-05-09 22:53:44.385  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas no DataFrame: 1565746\n",
      "\n",
      "Tempo total de execução: 15.11 segundos\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Início do temporizador total\n",
    "    tempo_inicio_total = time.time()   \n",
    "\n",
    "    # Consulta SQL: Filtrar propriedades da região sudeste\n",
    "    consulta_2 = \"\"\"\n",
    "    SELECT *\n",
    "    FROM temp_table\n",
    "    WHERE Uf IN ('SP', 'RJ', 'MG', 'ES')\n",
    "    \"\"\"\n",
    "\n",
    "    # Salvar os resultados da consulta no HDFS\n",
    "    df_consulta_2 = spark.sql(consulta_2)  # Segunda consulta do projeto\n",
    "    table_consulta_2 = \"projeto_consulta_2\"\n",
    "    df_consulta_2.write.mode(\"overwrite\").parquet(f\"hdfs://localhost:9000/tmp/hive/{table_consulta_2}\")\n",
    "    print(f\"Tabela {table_consulta_2} criada no HDFS com os resultados da consulta 2.\")\n",
    "    \n",
    "    # Ler a tabela criada no HDFS e exibir os resultados completos\n",
    "    consulta_2 = spark.read.parquet(f\"hdfs://localhost:9000/tmp/hive/{table_consulta_2}\")\n",
    "    numero_de_linhas = consulta_2.count()\n",
    "    display(consulta_2.limit(5).toPandas())    \n",
    "    print(f\"Número de linhas no DataFrame: {numero_de_linhas}\") \n",
    "\n",
    "    # Tempo total de execução\n",
    "    tempo_total = time.time() - tempo_inicio_total\n",
    "    print(f\"\\nTempo total de execução: {tempo_total:.2f} segundos\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro no processamento: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terceira Consulta SQL usando Hive do Projeto\n",
    "\n",
    "calcular quantas propriedades foram cadastradas por ano, utilizando a coluna data_inscricao e agrupando por ano. Aqui já fazemos uma transformação exibindo somente as colunas que não são vazias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela projeto_consulta_3 criada no HDFS com os resultados da consulta 3.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ano</th>\n",
       "      <th>Total_Propriedades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>227468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1240178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>1828786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>794779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>724856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>746570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020</td>\n",
       "      <td>463322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021</td>\n",
       "      <td>443942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022</td>\n",
       "      <td>368448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ano  Total_Propriedades\n",
       "0  2013                 743\n",
       "1  2014              227468\n",
       "2  2015             1240178\n",
       "3  2016             1828786\n",
       "4  2017              794779\n",
       "5  2018              724856\n",
       "6  2019              746570\n",
       "7  2020              463322\n",
       "8  2021              443942\n",
       "9  2022              368448"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas no DataFrame: 10\n",
      "\n",
      "Tempo total de execução: 1.61 segundos\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Início do temporizador total\n",
    "    tempo_inicio_total = time.time()   \n",
    "\n",
    "    # Consulta SQL: Contar propriedades cadastradas por ano, filtrando nulos\n",
    "    consulta_3 = \"\"\"\n",
    "    SELECT YEAR(`Data Inscricao`) AS Ano, COUNT(*) AS Total_Propriedades\n",
    "    FROM temp_table\n",
    "    WHERE `Data Inscricao` IS NOT NULL\n",
    "    GROUP BY YEAR(`Data Inscricao`)\n",
    "    ORDER BY Ano\n",
    "    \"\"\"\n",
    "\n",
    "    # Salvar os resultados da consulta no HDFS\n",
    "    df_consulta_3 = spark.sql(consulta_3)  # Terceira consulta do projeto\n",
    "    table_consulta_3 = \"projeto_consulta_3\"\n",
    "    df_consulta_3.write.mode(\"overwrite\").parquet(f\"hdfs://localhost:9000/tmp/hive/{table_consulta_3}\")\n",
    "    print(f\"Tabela {table_consulta_3} criada no HDFS com os resultados da consulta 3.\")\n",
    "    \n",
    "    # Ler a tabela criada no HDFS e exibir os resultados completos\n",
    "    consulta_3 = spark.read.parquet(f\"hdfs://localhost:9000/tmp/hive/{table_consulta_3}\")\n",
    "    numero_de_linhas = consulta_3.count()\n",
    "    display(consulta_3.toPandas())    \n",
    "    print(f\"Número de linhas no DataFrame: {numero_de_linhas}\") \n",
    "\n",
    "    # Tempo total de execução\n",
    "    tempo_total = time.time() - tempo_inicio_total\n",
    "    print(f\"\\nTempo total de execução: {tempo_total:.2f} segundos\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro no processamento: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quarta Consulta SQL usando Hive do Projeto\n",
    "\n",
    "calcular o percentual médio de área remanescente de vegetação nativa em relação à área total do proprietário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela projeto_consulta_4 criada no HDFS com os resultados da consulta 4.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percentual_Medio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.087406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Percentual_Medio\n",
       "0         18.087406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas no DataFrame: 1\n",
      "\n",
      "Tempo total de execução: 1.28 segundos\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Início do temporizador total\n",
    "    tempo_inicio_total = time.time()   \n",
    "\n",
    "    # Consulta SQL: Percentual médio de área remanescente de vegetação nativa\n",
    "    consulta_4 = \"\"\"\n",
    "    SELECT \n",
    "        AVG((`Area Remanescente Vegetacao Nativa` / `Area Do Imovel`) * 100) AS Percentual_Medio\n",
    "    FROM temp_table\n",
    "    \"\"\"\n",
    "\n",
    "    # Salvar os resultados da consulta no HDFS\n",
    "    df_consulta_4 = spark.sql(consulta_4)  # Quarta consulta do projeto\n",
    "    table_consulta_4 = \"projeto_consulta_4\"\n",
    "    df_consulta_4.write.mode(\"overwrite\").parquet(f\"hdfs://localhost:9000/tmp/hive/{table_consulta_4}\")\n",
    "    print(f\"Tabela {table_consulta_4} criada no HDFS com os resultados da consulta 4.\")\n",
    "    \n",
    "    # Ler a tabela criada no HDFS e exibir os resultados completos\n",
    "    consulta_4 = spark.read.parquet(f\"hdfs://localhost:9000/tmp/hive/{table_consulta_4}\")\n",
    "    numero_de_linhas = consulta_4.count()\n",
    "    display(consulta_4.toPandas())    \n",
    "    print(f\"Número de linhas no DataFrame: {numero_de_linhas}\") \n",
    "\n",
    "    # Tempo total de execução\n",
    "    tempo_total = time.time() - tempo_inicio_total\n",
    "    print(f\"\\nTempo total de execução: {tempo_total:.2f} segundos\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro no processamento: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quinta Consulta SQL usando Hive do Projeto\n",
    "\n",
    "contar as propriedades rurais por estado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela projeto_consulta_5 criada no HDFS com os resultados da consulta 5.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uf</th>\n",
       "      <th>Total_Propriedades_Rurais</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AC</td>\n",
       "      <td>45141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>114610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AM</td>\n",
       "      <td>73642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP</td>\n",
       "      <td>10116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BA</td>\n",
       "      <td>1012499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CE</td>\n",
       "      <td>314866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DF</td>\n",
       "      <td>17339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ES</td>\n",
       "      <td>108849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GO</td>\n",
       "      <td>199690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MA</td>\n",
       "      <td>273642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MG</td>\n",
       "      <td>989446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MS</td>\n",
       "      <td>79914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MT</td>\n",
       "      <td>170205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PA</td>\n",
       "      <td>279598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PB</td>\n",
       "      <td>170851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PE</td>\n",
       "      <td>339371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PI</td>\n",
       "      <td>255052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PR</td>\n",
       "      <td>496164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RJ</td>\n",
       "      <td>58923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RN</td>\n",
       "      <td>89357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RO</td>\n",
       "      <td>147287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RR</td>\n",
       "      <td>22687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RS</td>\n",
       "      <td>606454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SC</td>\n",
       "      <td>374918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SE</td>\n",
       "      <td>94418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SP</td>\n",
       "      <td>408528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>TO</td>\n",
       "      <td>85537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Uf  Total_Propriedades_Rurais\n",
       "0   AC                      45141\n",
       "1   AL                     114610\n",
       "2   AM                      73642\n",
       "3   AP                      10116\n",
       "4   BA                    1012499\n",
       "5   CE                     314866\n",
       "6   DF                      17339\n",
       "7   ES                     108849\n",
       "8   GO                     199690\n",
       "9   MA                     273642\n",
       "10  MG                     989446\n",
       "11  MS                      79914\n",
       "12  MT                     170205\n",
       "13  PA                     279598\n",
       "14  PB                     170851\n",
       "15  PE                     339371\n",
       "16  PI                     255052\n",
       "17  PR                     496164\n",
       "18  RJ                      58923\n",
       "19  RN                      89357\n",
       "20  RO                     147287\n",
       "21  RR                      22687\n",
       "22  RS                     606454\n",
       "23  SC                     374918\n",
       "24  SE                      94418\n",
       "25  SP                     408528\n",
       "26  TO                      85537"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas no DataFrame: 27\n",
      "\n",
      "Tempo total de execução: 1.16 segundos\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Início do temporizador total\n",
    "    tempo_inicio_total = time.time()   \n",
    "\n",
    "    # Consulta SQL: Contagem de propriedades rurais por estado\n",
    "    consulta_5 = \"\"\"\n",
    "    SELECT Uf, COUNT(*) AS Total_Propriedades_Rurais\n",
    "    FROM temp_table    \n",
    "    GROUP BY Uf\n",
    "    ORDER BY Uf\n",
    "    \"\"\"\n",
    "\n",
    "    # Salvar os resultados da consulta no HDFS\n",
    "    df_consulta_5 = spark.sql(consulta_5)  # Quinta consulta do projeto\n",
    "    table_consulta_5 = \"projeto_consulta_5\"\n",
    "    df_consulta_5.write.mode(\"overwrite\").parquet(f\"hdfs://localhost:9000/tmp/hive/{table_consulta_5}\")\n",
    "    print(f\"Tabela {table_consulta_5} criada no HDFS com os resultados da consulta 5.\")\n",
    "    \n",
    "    # Ler a tabela criada no HDFS e exibir os resultados completos\n",
    "    consulta_5 = spark.read.parquet(f\"hdfs://localhost:9000/tmp/hive/{table_consulta_5}\")\n",
    "    numero_de_linhas = consulta_5.count()\n",
    "    display(consulta_5.toPandas())    \n",
    "    print(f\"Número de linhas no DataFrame: {numero_de_linhas}\") \n",
    "\n",
    "    # Tempo total de execução\n",
    "    tempo_total = time.time() - tempo_inicio_total\n",
    "    print(f\"\\nTempo total de execução: {tempo_total:.2f} segundos\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro no processamento: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sexta Consulta SQL usando Hive do Projeto\n",
    "\n",
    "calcular a distância entre a maior propriedade e Brasília utilizando as coordenadas de centróide da propriedade.\n",
    "\n",
    "**Usaremos a fórmula de Haversine para calcular a distância entre dois pontos geográficos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela projeto_consulta_6 criada no HDFS com os resultados da consulta 6.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area Do Imovel</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Distancia_Brasilia</th>\n",
       "      <th>Uf</th>\n",
       "      <th>Municipio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.420079e+06</td>\n",
       "      <td>-5.475619</td>\n",
       "      <td>-68.888188</td>\n",
       "      <td>2562.129615</td>\n",
       "      <td>AM</td>\n",
       "      <td>Jutaí</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Area Do Imovel  Latitude  Longitude  Distancia_Brasilia  Uf Municipio\n",
       "0    2.420079e+06 -5.475619 -68.888188         2562.129615  AM     Jutaí"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas no DataFrame: 1\n",
      "\n",
      "Tempo total de execução: 19.79 segundos\n"
     ]
    }
   ],
   "source": [
    "def calcular_distancia(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calcula a distância entre dois pontos geográficos usando a fórmula de Haversine.\n",
    "    \"\"\"\n",
    "    # Converter de graus para radianos\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Fórmula de Haversine\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    r = 6371  # Raio da Terra em quilômetros\n",
    "    return c * r\n",
    "\n",
    "try:\n",
    "    # Início do temporizador total\n",
    "    tempo_inicio_total = time.time()   \n",
    "\n",
    "    # Consulta SQL: Selecionar a maior propriedade\n",
    "    consulta_6 = \"\"\"\n",
    "    SELECT `Area Do Imovel`, `Latitude`, `Longitude`, `Uf`, `Municipio`\n",
    "    FROM temp_table\n",
    "    ORDER BY `Area Do Imovel` DESC\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "\n",
    "    # Executar a consulta para obter a maior propriedade\n",
    "    df_consulta_6 = spark.sql(consulta_6)\n",
    "    resultado = df_consulta_6.collect()[0]  # Obter o resultado da consulta\n",
    "\n",
    "    # Extrair as coordenadas da maior propriedade e outras informações\n",
    "    latitude_propriedade = resultado[\"Latitude\"]\n",
    "    longitude_propriedade = resultado[\"Longitude\"]\n",
    "    area_propriedade = resultado[\"Area Do Imovel\"]\n",
    "    uf_propriedade = resultado[\"Uf\"]\n",
    "    municipio_propriedade = resultado[\"Municipio\"]\n",
    "\n",
    "    # Coordenadas de Brasília\n",
    "    latitude_brasilia = -15.796943053171708\n",
    "    longitude_brasilia = -47.891638482569476\n",
    "\n",
    "    # Calcular a distância usando a fórmula de Haversine\n",
    "    distancia = calcular_distancia(latitude_propriedade, longitude_propriedade, latitude_brasilia, longitude_brasilia)\n",
    "    \n",
    "    # Criar um DataFrame com os resultados\n",
    "    data = [(area_propriedade, latitude_propriedade, longitude_propriedade, distancia, uf_propriedade, municipio_propriedade)]\n",
    "    columns = [\"Area Do Imovel\", \"Latitude\", \"Longitude\", \"Distancia_Brasilia\", \"Uf\", \"Municipio\"]\n",
    "    df_resultado = spark.createDataFrame(data, columns)\n",
    "\n",
    "    # Salvar os resultados da consulta no HDFS\n",
    "    table_consulta_6 = \"projeto_consulta_6\"\n",
    "    df_resultado.write.mode(\"overwrite\").parquet(f\"hdfs://localhost:9000/tmp/hive/{table_consulta_6}\")\n",
    "    print(f\"Tabela {table_consulta_6} criada no HDFS com os resultados da consulta 6.\")\n",
    "    \n",
    "    # Ler a tabela criada no HDFS e exibir os resultados completos\n",
    "    consulta_6 = spark.read.parquet(f\"hdfs://localhost:9000/tmp/hive/{table_consulta_6}\")\n",
    "    numero_de_linhas = consulta_6.count()\n",
    "    display(consulta_6.toPandas())    \n",
    "    print(f\"Número de linhas no DataFrame: {numero_de_linhas}\") \n",
    "\n",
    "    # Tempo total de execução\n",
    "    tempo_total = time.time() - tempo_inicio_total\n",
    "    print(f\"\\nTempo total de execução: {tempo_total:.2f} segundos\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro no processamento: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sétima Consulta SQL usando Hive do Projeto\n",
    "\n",
    "calcular a média de todas as propriedades e, em seguida, determinar quantas propriedades por estado estão acima da média.\n",
    "\n",
    "**Vamos usar GROUP BY para agrupar os estados e contar as propriedades acima da média.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela projeto_consulta_7 criada no HDFS com os resultados da consulta 7.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uf</th>\n",
       "      <th>Total_Propriedades_Acima_Media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AC</td>\n",
       "      <td>10559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>3641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AM</td>\n",
       "      <td>21412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP</td>\n",
       "      <td>3759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BA</td>\n",
       "      <td>50508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CE</td>\n",
       "      <td>22931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DF</td>\n",
       "      <td>1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ES</td>\n",
       "      <td>6378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GO</td>\n",
       "      <td>61385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MA</td>\n",
       "      <td>42202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MG</td>\n",
       "      <td>107875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MS</td>\n",
       "      <td>33762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MT</td>\n",
       "      <td>78569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PA</td>\n",
       "      <td>86698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PB</td>\n",
       "      <td>8309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PE</td>\n",
       "      <td>12274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PI</td>\n",
       "      <td>27223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PR</td>\n",
       "      <td>32005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RJ</td>\n",
       "      <td>6326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RN</td>\n",
       "      <td>7519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RO</td>\n",
       "      <td>32665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RR</td>\n",
       "      <td>8532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RS</td>\n",
       "      <td>40274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SC</td>\n",
       "      <td>10667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SE</td>\n",
       "      <td>3177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SP</td>\n",
       "      <td>45229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>TO</td>\n",
       "      <td>33389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Uf  Total_Propriedades_Acima_Media\n",
       "0   AC                           10559\n",
       "1   AL                            3641\n",
       "2   AM                           21412\n",
       "3   AP                            3759\n",
       "4   BA                           50508\n",
       "5   CE                           22931\n",
       "6   DF                            1040\n",
       "7   ES                            6378\n",
       "8   GO                           61385\n",
       "9   MA                           42202\n",
       "10  MG                          107875\n",
       "11  MS                           33762\n",
       "12  MT                           78569\n",
       "13  PA                           86698\n",
       "14  PB                            8309\n",
       "15  PE                           12274\n",
       "16  PI                           27223\n",
       "17  PR                           32005\n",
       "18  RJ                            6326\n",
       "19  RN                            7519\n",
       "20  RO                           32665\n",
       "21  RR                            8532\n",
       "22  RS                           40274\n",
       "23  SC                           10667\n",
       "24  SE                            3177\n",
       "25  SP                           45229\n",
       "26  TO                           33389"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas no DataFrame: 27\n",
      "\n",
      "Tempo total de execução: 1.59 segundos\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Início do temporizador total\n",
    "    tempo_inicio_total = time.time()   \n",
    "\n",
    "    # Consulta SQL: Calcular a média de área de todas as propriedades\n",
    "    consulta_media = \"\"\"\n",
    "    SELECT AVG(`Area Do Imovel`) AS Media_Area\n",
    "    FROM temp_table\n",
    "    \"\"\"\n",
    "    df_media = spark.sql(consulta_media)\n",
    "    media_area = df_media.collect()[0][\"Media_Area\"]\n",
    "\n",
    "    # Consulta SQL: Contagem de propriedades por estado acima da média\n",
    "    consulta_7 = f\"\"\"\n",
    "    SELECT Uf, COUNT(*) AS Total_Propriedades_Acima_Media\n",
    "    FROM temp_table\n",
    "    WHERE `Area Do Imovel` > {media_area}\n",
    "    GROUP BY Uf\n",
    "    ORDER BY Uf\n",
    "    \"\"\"\n",
    "\n",
    "    # Salvar os resultados da consulta no HDFS\n",
    "    df_consulta_7 = spark.sql(consulta_7)  # Sétima consulta do projeto\n",
    "    table_consulta_7 = \"projeto_consulta_7\"\n",
    "    df_consulta_7.write.mode(\"overwrite\").parquet(f\"hdfs://localhost:9000/tmp/hive/{table_consulta_7}\")\n",
    "    print(f\"Tabela {table_consulta_7} criada no HDFS com os resultados da consulta 7.\")\n",
    "    \n",
    "    # Ler a tabela criada no HDFS e exibir os resultados completos\n",
    "    consulta_7 = spark.read.parquet(f\"hdfs://localhost:9000/tmp/hive/{table_consulta_7}\")\n",
    "    numero_de_linhas = consulta_7.count()\n",
    "    display(consulta_7.toPandas())    \n",
    "    print(f\"Número de linhas no DataFrame: {numero_de_linhas}\") \n",
    "\n",
    "    # Tempo total de execução\n",
    "    tempo_total = time.time() - tempo_inicio_total\n",
    "    print(f\"\\nTempo total de execução: {tempo_total:.2f} segundos\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro no processamento: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
